
# ğŸ“½ï¸ One Click Video Breakdown - Multimodal AI Pipeline

> **Transcribe, summarize, translate, and chat with any video â€” in one seamless AI-powered interface.**

---

## ğŸ” Overview

This interactive web application enables users to upload or link to a video and automatically:

- ğŸ™ï¸ Transcribe speech using Whisper
- âœï¸ Generate a summary with GPT-4
- ğŸŒ Translate content into any language
- ğŸ¤– Ask questions â€” and get answers based strictly on the video

It integrates cutting-edge AI models using **Whisper**, **GPT-4**, **LangChain**, and **Gradio**, forming a complete **multimodal pipeline**.

---

## ğŸ¯ Motivation

In an era of long-form video content â€” podcasts, interviews, lectures, and tutorials â€” users often struggle to extract key insights without watching the full video.  
This project was built to:

- â³ **Save time** by automatically transcribing and summarizing video content.
- ğŸŒ **Break language barriers** by translating content into any language.
- ğŸ’¬ **Enable interactive exploration** through a chatbot that answers specific questions based strictly on video content.
- â™¿ **Support accessibility** for Deaf and hard-of-hearing users by providing high-quality, readable transcripts and summaries of spoken content.

---

## ğŸš€ Key Features

### ğŸ”„ Multimodal Pipeline
- ğŸ§ **Speech-to-Text**: OpenAI Whisper for transcription
- ğŸ§  **Summarization**: GPT-4 condenses the transcript
- ğŸŒ **Translation**: Translate to any language, powered by GPT
- ğŸ”Š **Text-to-Speech**: Convert translated text into natural audio using OpenAI TTS (Nova, Shimmer, Echo voices)

### ğŸ§  AI-Powered Q&A
- ğŸ’¬ Ask any question about the video
- âœ… Answers are **fact-checked** using semantic vector search
- ğŸ›¡ï¸ Non-relevant questions are rejected with: "This topic isn't covered in the video."
- ğŸŒ Arabic support: questions are translated internally to English for processing

### ğŸ” Vector Search & Memory
- Transcripts are chunked and embedded via OpenAI Embeddings
- ChromaDB powers fast and relevant context retrieval
- Agent memory is preserved using LangChain's buffer

### ğŸ–¥ï¸ Interactive Interface (Gradio)
- ğŸ“¥ Upload videos or paste YouTube URLs
- ğŸ“„ View and hide transcripts dynamically
- ğŸŒ Choose your translation language and voice style
- ğŸ¤– Chat in a dedicated tab with real-time response

---

## ğŸ§  Tech Stack

| Technology           | Role                                                              |
|----------------------|-------------------------------------------------------------------|
| **Whisper**          | Speech-to-text transcription                                      |
| **OpenAI GPT-4**     | Summarization, translation, and question answering                |
| **OpenAI TTS**       | Audio playback of translated text                                 |
| **LangChain**        | Agent framework, vector search, memory                            |
| **langchain-openai** | Updated OpenAI wrappers (ChatOpenAI & OpenAIEmbeddings)           |
| **ChromaDB**         | Vector storage and retrieval for semantic search                  |
| **Gradio**           | Web UI framework                                                  |
| **yt-dlp + ffmpeg**  | YouTube download & audio extraction                               |

---

## ğŸ“ Code Structure

The entire application is implemented in **one Python file**, including:

- Model loading
- Transcription and summarization
- Vector DB creation
- Agent-based QA system
- Translation + TTS
- Full Gradio UI

---

## âš™ï¸ Setup Guide

### 1. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # For Windows: venv\Scripts\activate
```

### 2. Install Requirements
```bash
pip install -r requirements.txt
```

### 3. Set API Keys
```bash
export OPENAI_API_KEY=sk-...
export LANGCHAIN_API_KEY=...
```

### 4. Run the App
```bash
python your_script_name.py
```

---

## ğŸŒ Deployment Options

- ğŸ’» **Localhost**: Automatically runs at `http://localhost:7860`
- â˜ï¸ **Hugging Face Spaces** / **Streamlit Cloud** (requires light UI adaptation)
- ğŸ” **LangSmith**: Trace LangChain agent interactions for debugging and optimization

---

## ğŸš§ Limitations

- Whisper accuracy may degrade with noisy audio
- GPT-generated answers depend on quality of transcript chunks
- Voice options limited to available OpenAI TTS models
- Agent strictly answers based only on the video transcript; off-topic questions are rejected with: "This topic isn't covered in the video."

---

## ğŸ’¡ Future Enhancements

- â±ï¸ Add clickable timestamps to summaries and chatbot answers
- ğŸ“„ Export transcripts and summaries to PDF/Word
- ğŸ˜Š Add sentiment analysis to highlight emotional tone of the video
- ğŸ‘¤ Add user login for history/multi-session use
- ğŸ“Š Show source chunks or confidence in chatbot answers

---
##  Demo videos:
https://drive.google.com/drive/folders/1JGl3VrH6q8_mV9FxhsRfyZr7d1N4FPNu?usp=share_link

## ğŸ™‹ Contact

Built with â¤ï¸ by **Raghad Alkhudair**  
Feel free to reach out with ideas, questions, or contributions.

---
